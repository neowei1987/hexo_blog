---
title: 分布式系统-可用性
date: 2022-02-24 10:01:03
tags: 
- 分布式系统
---

系统在困境（adversity）（硬件故障、软件故障、人为错误）中仍可正常工作（正确完成功能，并能达到期望的性能水准）。

plan挂了之后，系统能不能活下来？ 有没有负责兜底的PlanB。

造成错误的原因叫做故障（fault），能预料并应对故障的系统特性可称为容错（fault-tolerant）或韧性（resilient）。

注意故障（fault）不同于失效（failure）【2】。故障通常定义为系统的**一部分**状态偏离其标准，而失效则是系统作为一个**整体**停止向用户提供服务。故障的概率不可能降到零，因此最好设计容错机制以防因故障而导致失效。

## 影响可用性的因素

### 雪崩

两个导火索：

- 下游或者本身机器故障导致latency增加
- 上游请求qps变高

实际的并发超过了最大能支持的并发（当下游变慢后，该值迅速会下降），过载就发生了。过载不可怕，如果上游不重试，系统终将恢复。

## 每个SLA级别需要做的事情

感觉一下提高1个9，难度有多大。

三个9: 非核心业务可以容忍

四个9: 核心业务

运维值班体系、业务变更流程、故障处理流程、更加完善的系统故障排查工具、灰度发布（确保服务可回滚）

五个9: 必须让机器来自动处理恢复！

尽量思考故障发生后应该怎么办

考虑点：如何自动的发现故障、如何自动化的应对故障、系统运维-尽量避免故障发生

具体方法：failover(故障转移)、超时控制、服务降级、熔断限流

failover:

- 完全对等
- 非完全对等（例如存在主备节点，心跳，选择paxos, raft等）

## 如何提高可用性

1. 每个系统，自己的最大处理能力是多少要做到清清楚楚。
2. 每个系统要有能力发现哪些是有效的请求，哪些是无效的请求。
3. 前端系统有保护后端系统的义务，sla中承诺多大的能力，就只给到后端多大的压力。这就要求每一个前后端接口的地方，都有明确的负载约定，一环扣一环。
4. 当过载发生时，该拒绝的请求（1、超出整个系统处理能力范围的；2、已经超时的无效请求）越早拒绝越好
5. 对于用户的重试行为，要适当的延缓。例如登录发现后端响应失败，再重新展现登录页面前，可以适当延时几秒钟，并展现进度条等友好界面。当多次重试还失败的情况下，要安抚用户。
6. 产品特性设计和发布上，要尽量避免某个时刻导致大量用户集体触发某些请求的设计。发布的时候注意灰度。
7. 中间层server对后端发送请求，重试机制要慎用，一定要用的话要有严格频率控制。
8. 当雪球发生了，直接清空雪球队列（例如重启进程可以清空socket缓冲区）可能是快速恢复的有效方法。
9. 过载保护很重要的一点，不是说要加强系统性能、容量，成功应答所有请求，而是保证在高压下，系统的服务能力不要陡降到0，而是顽强的对外展现最大有效处理能力。

### 冗余

解决高可用，只有一个方法，就是冗余。

通过冗余更多的机器，来应对机器的硬件故障或者彼此之间的网络故障。

#### 多机房部署

通过多机房部署来增加冗余。

多活的好处

1. 响应时间短、提升用户体验
2. 服务高可用
3. 降低成本

- 廉价的机器（非洲用户访问非洲的机器）
- 流量的分摊（西方节日时，流量通过亚洲来分摊）

如何做到异地多活（必须要解决的一些问题）

1. 接入层流量控制：用户默认访问哪个DC？什么时候做切换？ 如何控制这个切换过程？

2. 各DC业务逻辑一致：对于用户来说， 他的流量被调度前后，业务逻辑是一致的。 比如facebook上有一些内容对于亚洲用户是不可见的，不能因为亚洲用户的流量被迁移到了美洲机房，这个限制就失效了。

3. 跨DC的实时数据同步与冲突处理：还是以fb为例， 如果访问非洲机房的用户A给访问南美洲机房的用户B的一个帖子点了赞， 那么B应该能及时收到相关的通知。这背后就依赖数据的实时同步。
在多活情况下， 多DC的数据写入势必会引入数据的冲突， 比如facebook位于美东的的审核系统和位于东南亚的用户同时操作了一条帖子， 就会产生数据的冲突。

4. 提供全球级别的强一致性
对于大多数业务而言， 我们只需要最终一致性即可（比如点赞之类的计数）。 但是某些业务，需要全球的强一致保障(比如下
单、支付之类的操作）。

**同城多机房**：延迟1～3ms

主要看接口的实现（如果有几十次的跨机房交互，这种是不可接受的）

实现相对比较简单

单机房写入；每一个机房近读取本机房的缓存与数据

如果数据发生变更，需要做两边机房缓存的清理，一般通过canal订阅数据库变更

![同城多活示意图](http://cdn.b5mang.com/202132021118.png)

**国内异地多机房**:延迟50ms以内

尽量减少跨机房的调用；而应该避免跨机房的数据库与缓存操作

多机房写入，按照用户或者其他业务维度来进行流量分割，使得一部分流量总是请求A机房，而另外的总是请求B机房。

根据业务需要，选择满足：
(1）一致性（如果选择了一致性，那么可用性便得不到100%保障）
(2）可用性（如果选择了可用性，那么一致性需要事后做补偿）

数据同步方式有两种：
（1）基于存储系统主从复制：同步redis、Mysql等
（2）基于消息队列：同步缓存、HBase的数据

![异步多活示意图](http://cdn.b5mang.com/20213202149.png)

**跨国多机房**：延迟在100～200ms

避免跨机房的调用，而只能做异步同步

---

除此以外，我们还需要提一点，就是防止系统被瞬间的异常拖死，也就是系统能够自己保护好自己。

### 过载保护

异常有内外两种，一种是外部流量特别高，一种是某一个依赖故障导致系统响应变慢。

这里的课题应该包括：熔断、限流、超时控制、全局超时控制、服务降级（区分核心流程与非核心流程）

#### 过载保护方案

这里推荐一种方案：在该系统每个机器上新增一个进程：interface进程。

Interface进程能够快速的从socket缓冲区中取得请求，打上当前时间戳，压入channel。

业务处理进程从channel中获取请求和该请求的时间戳，如果发现时间戳早于当前时间减去超时时间（即已经超时，处理也没有意义），就直接丢弃该请求，或者应答一个失败报文。

Channel是一个先进先出的通信方式，可以是socket，也可以是共享内存、消息队列、或者管道，不限。

Socket缓冲区要设置合理，如果过大，导致及时interface进程都需要处理长时间才能清空该队列，就不合适了。

建议的大小上限是：缓存住超时时间内interface进程能够处理掉的请求个数（注意考虑网络通讯中的元数据）。

参考：https://www.sohu.com/a/211248633_472869