---
title: 计算机-主存储
date: 2022-12-14 21:03:03
updated:
description: 
mathjax: true
categories:
tags: [知识体系]
---

## 0. 主存储

### dpdk高性能

#### 轮询机制

在包处理时，采用轮询机制，而避免中断，有利于减少上下文切换的开销，规避不必要的内存拷贝和系统调用。

#### 亲和性与独占

特定任务可以被指定只在某个核上工作，避免线程在不同核间频繁切换，保证更多的cache命中

设置CPU亲和性，让程序近运行在指定的核上，仅读取指定网卡的指定队列，从而避免数据竞争

无锁循环队列

并行指令，从而加速访问  

<!-- more -->

#### CPU Cache 加速

- cache行对齐
- 预取数据，CPU提供了指令来供程序员使用，提前把要读区的数据从内存加载到对应的Cache
- 每个核尽量不与其他核共享数据，以减少Cache保持一致性带来的额外成本

#### 引入大页表

矛盾：TLB大小有限 VS 尽可能高的查询命中率

解法：但是一个常规页4k，假设一个程序用了512页，总共2MB，这就需要TLB里至少方下512个页表项才能保证每次都能命中，但TLB大小有限。所以为了减少TLB不命中的情况，可以使用大页，以1G为单位进行分页。

降低访存开销：利用内存大页HUGEPAGE降低TLB miss，利用内存多通道交错访问提高内存访问有效带宽

#### 克服NUMA

为了克服SMP的总线负担大的问题，引入NUMA，但是引入了新的问题：访问远程内存效率低下。

DPDK为了克服NUMA的弊端，采取了如下措施：

①Pre-corememory。每个核都有属于自己的内存，经常访问的数据结构有自己的备份。这样既满足了本地内存的需要，又可以避免cache一致性问题。

②本地设备本地处理。如果一个PCI设备在node0上，那这个设备就由Node0处理。比如：

q = rte_zmalloc_socked\t(“fm10k”,sizeof(*q), RTE_CACHE_LINE_SIZE, socket_id);

#### 充分利用DDIO

没有DDIO的情况下，处理一个报文，CPU和网卡需要多次访问内存，而内存又很慢，造成CPU长时间等待内存。

DDIO让外部网卡和cpu通过LLC Cache交换数据，绕过内存。但是报文要存在LLC Cache中，增加了对LLC Cache的容量需求。（*LLC = Last Level Cache）
